{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Gutenberg corpus\n",
    "data= gutenberg.raw('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespeare-hamlet.txt', 'w', ) as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('shakespeare-hamlet.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58894cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af76909",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "input_sequences =np.array( pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x,y=input_sequences[:,:-1],input_sequences[:,-1]\n",
    "y= tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48442de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac355641",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, tokenizer, text,max_sequence_length):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    if len(token_list) >= max_sequence_length - 1:\n",
    "        token_list = token_list[-(max_sequence_length - 1):]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=-1)\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"to be or not to be \"\n",
    "print(f\"Input text: {input_text}\")\n",
    "max_sequence_length=model.input_shape[1]+1\n",
    "predicted_word = predict_next_word(model, tokenizer, input_text, max_sequence_length)\n",
    "print(f\"Predicted next word: {predicted_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('next_word_predictor.h5')\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
